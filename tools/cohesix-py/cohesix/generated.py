# Generated by coh-rtc. DO NOT EDIT BY HAND.
# Author: Lukas Bower
# Purpose: Provide manifest-derived defaults for the Cohesix Python client.

DEFAULTS = {
    "manifest_sha256": "dbb26505c014d77a48d9d1487a8cddce63ff9dabaa24e9a997eb53f2bf8859e5",
    "secure9p": {"msize": 8192, "walk_depth": 8},
    "console": {
        "max_line_len": 256,
        "max_path_len": 96,
        "max_json_len": 192,
        "max_id_len": 32,
        "max_echo_len": 128,
        "max_ticket_len": 224,
    },
    "ticket_limits": {
        "max_scopes": 8,
        "max_scope_path_len": 128,
        "max_scope_rate_per_s": 64,
        "bandwidth_bytes": 131072,
        "cursor_resumes": 16,
        "cursor_advances": 256,
    },
    "paths": {
        "queen_ctl": "/queen/ctl",
        "queen_lifecycle_ctl": "/queen/lifecycle/ctl",
        "log": "/log/queen.log",
    },
    "telemetry_ingest": {
        "max_segments_per_device": 4,
        "max_bytes_per_segment": 32768,
        "max_total_bytes_per_device": 131072,
        "eviction_policy": "evict-oldest",
    },
    "telemetry_push": {
        "schema": "cohsh-telemetry-push/v1",
        "max_record_bytes": 4096,
    },
    "coh": {
        "mount": {
            "root": "/",
            "allowlist": [
                "/proc",
                "/queen",
                "/worker",
                "/log",
                "/gpu",
                "/host"
            ]
        },
        "telemetry": {
            "root": "/queen/telemetry",
            "max_devices": 32,
            "max_segments_per_device": 4,
            "max_bytes_per_segment": 32768,
            "max_total_bytes_per_device": 131072,
        },
        "run": {
            "lease": {
                "schema": "gpu-lease/v1",
                "active_state": "ACTIVE",
                "max_bytes": 1024,
            },
            "breadcrumb": {
                "schema": "gpu-breadcrumb/v1",
                "max_line_bytes": 512,
                "max_command_bytes": 256,
            },
        },
        "peft": {
            "export": {
                "root": "/queen/export/lora_jobs",
                "max_telemetry_bytes": 131072,
                "max_policy_bytes": 8192,
                "max_base_model_bytes": 1024,
            },
            "import": {
                "registry_root": "out/model_registry",
                "max_adapter_bytes": 67108864,
                "max_lora_bytes": 65536,
                "max_metrics_bytes": 65536,
                "max_manifest_bytes": 8192,
            },
            "activate": {
                "max_model_id_bytes": 128,
                "max_state_bytes": 4096,
            },
        },
    },
    "retry": {
        "max_attempts": 3,
        "backoff_ms": 200,
        "ceiling_ms": 2000,
        "timeout_ms": 5000,
    },
    "examples": {
        "gpu_id": "GPU-0",
        "mig_gpu_id": "MIG-0",
        "job_id": "job_8932",
        "model_id": "llama3-edge-v7",
        "device_id": "device-1",
        "output_root": "out/examples",
    },
}
